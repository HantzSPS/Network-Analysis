{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 4  \n",
    "Spam Classifier  \n",
    "Hantz Angrand  \n",
    "4/4/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Classifier can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set\n",
    "  \n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder). \n",
    "\n",
    "For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out task is to distinguish between two types of emails, “spam” and “non-spam” often called “ham”. The machine learning classifier will detect that an email is spam if it is characterised by certain features. The textual content of the email – plays a big role on detection of spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the enron dataset.  The dataset can be downloaded from here https://labs-repos.iit.demokritos.gr/skel/i-config/downloads/enron-spam/preprocessed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1.- Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries and unarchived the file\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "import tarfile\n",
    " \n",
    "def untar(fname):\n",
    "    if (fname.endswith(\"tar.gz\")):\n",
    "        tar = tarfile.open(fname)\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "        print (\"Extracted in Current Directory\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted in Current Directory\n"
     ]
    }
   ],
   "source": [
    "untar('enron1.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create spam and ham list\n",
    "def spamhamlist(folder):\n",
    "    #Empty list\n",
    "    sh_list =[]\n",
    "    f_list = os.listdir(folder)\n",
    "    for fl in f_list:\n",
    "        f = open(folder + fl, 'rb')\n",
    "        rf = f.read()\n",
    "        sh_list.append(rf)\n",
    "    f.close()\n",
    "    return sh_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create spam lists\n",
    "spam = spamhamlist('enron1/spam/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ham list\n",
    "ham = spamhamlist('enron1/ham/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the two list and keep the labels\n",
    "mails = [(email,'spam') for email in spam]\n",
    "mails +=[(email, 'ham') for email in ham]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mails dataset length is  5172\n"
     ]
    }
   ],
   "source": [
    "#get the length of mails\n",
    "print(\"Mails dataset length is \", len(mails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2. Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Firts shuffle the data\n",
    "import random\n",
    "random.shuffle(mails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'Subject: do you like computers\\r\\nincredible offers :\\r\\nwindows x * p pro 2 oo 2 5 o dollars\\r\\no * r * d * e * r : http : / / epsom . gaulhafmk . com\\r\\nwe also have :\\r\\n- ms picture it premium 9\\r\\n- ms sql server 2 ooo enterprise edition\\r\\n- ms sql server 2 ooo enterprise edition\\r\\nthe offer is valid untill may 16 th\\r\\nstock is limited\\r\\ncheck out\\r\\njudith lanier\\r\\nmasseur\\r\\nindrel industria refrigera ? ? o londrinense , londrina 86072000 , brazil\\r\\nphone : 911 - 547 - 3116\\r\\nmobile : 737 - 434 - 1646\\r\\nemail : otxfcc @ satyamonline . com\\r\\nthis message is beng sent to confirm your account . please do not reply directly to this message\\r\\nthis version is a 27 day definite freeware\\r\\nnotes :\\r\\nthe contents of this message is for understanding and should not be ankara conferee\\r\\nturnout lou venezuela\\r\\ntime : sat , 07 may 2005 10 : 39 : 39 + 0200\\r\\n',\n",
       "  'spam')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mails[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hangr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "#Splitting the text by white spaces and punctuation marks and linking the different forms of the same word and finally convert \n",
    "#all words to lower cases.\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "def preprocess(sent):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word.lower()) for word in word_tokenize(str(sent))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the feature characterising spam and ham emails\n",
    "#First remove stop words, those are words that are not useful\n",
    "from nltk.corpus import stopwords\n",
    "stoplist = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each word that is not in the stoplist get how frequently it appears or simply register the fact that the word occurs in the email\n",
    "from collections import Counter\n",
    "def get_features(text, setting):\n",
    "    if setting =='bow':\n",
    "        return {word: count for word, count in Counter(preprocess(text)).items() if not word in stoplist }\n",
    "    else:\n",
    "        return {word: True for word in preprocess(text) if not word in stoplist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extarct the features using the bag of word models\n",
    "feats =[(get_features(email, 'bow'), label) for (email,label) in mails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats =[(get_features(email, ''), label) for (email,label) in mails]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into a train set and a test set that wu will be used to evaluate the model\n",
    "#train function will use the features set defined above and a proportion that we set as 0.8\n",
    "from nltk import NaiveBayesClassifier, classify\n",
    "def train(features, prop):\n",
    "    train_size = int(len(features) * prop)\n",
    "    train_set = features[:train_size]\n",
    "    test_set = features[train_size:]\n",
    "    print(\"Training set size \" + str(len(train_set)) + \" mails\")\n",
    "    print(\"Test set size \" + str(len(test_set)) + \" mails\")\n",
    "    #Train naives bayes model\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    return train_set, test_set, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 4137 mails\n",
      "Test set size 1035 mails\n"
     ]
    }
   ],
   "source": [
    "#train the classifier\n",
    "train_set, test_set, classifier=train(feats, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the classification by evaluating its performance on the test dataset. we are going to use the 20% to test our data\n",
    "def evaluate(train_set, test_set, classifier):\n",
    "    print(\"Accuracy of the training set \" + str(round(classify.accuracy(classifier, train_set) * 100)) + \"%\")\n",
    "    print(\"Accuracy of the test set \" + str(round(classify.accuracy(classifier, test_set)*100)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the training set 97%\n",
      "Accuracy of the test set 95%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy on the training_set, test set\n",
    "evaluate(train_set, test_set, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the perspective of natural language we can try to determine which word the classifier finds more important to classify an email as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     ect = True              ham : spam   =    188.4 : 1.0\n",
      "                     hou = True              ham : spam   =    184.8 : 1.0\n",
      "             \\r\\nsubject = True              ham : spam   =    184.8 : 1.0\n",
      "                pm\\r\\nto = True              ham : spam   =    178.2 : 1.0\n",
      "                    2004 = True             spam : ham    =    150.5 : 1.0\n",
      "                   meter = True              ham : spam   =    102.4 : 1.0\n",
      "              medication = True             spam : ham    =     91.0 : 1.0\n",
      "                    spam = True             spam : ham    =     87.7 : 1.0\n",
      "                     sex = True             spam : ham    =     79.7 : 1.0\n",
      "                   cheap = True             spam : ham    =     76.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Most informative words\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, \"medication\" is around 102 times more likely to be spam than ham and sex is 79 times to be spam than ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Different dataset to test our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages, tagged acording being ham (legitimate) or spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "import csv\n",
    "def load_data(Train=False):\n",
    "    data = []\n",
    "    # Read the training data\n",
    "    f = open('sms/spam.csv')\n",
    "    reader = csv.reader(f)\n",
    "    next(reader, None)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572\n"
     ]
    }
   ],
   "source": [
    "#Number of records in the dataset\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 'ham']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extarct the features using the bag of word models\n",
    "feats =[(get_features(email, 'bow'), label) for (email,label) in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats =[(get_features(email, ''), label) for (email,label) in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size 4457 mails\n",
      "Test set size 1115 mails\n"
     ]
    }
   ],
   "source": [
    "##Training a classifier\n",
    "train_set, test_set, classifier=train(feats, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the training set 90%\n",
      "Accuracy of the test set 90%\n"
     ]
    }
   ],
   "source": [
    "##Evaluation of the model\n",
    "evaluate(train_set, test_set, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 service = True             spam : ham    =    154.8 : 1.0\n",
      "                   nokia = True             spam : ham    =    103.6 : 1.0\n",
      "                     txt = True             spam : ham    =     93.7 : 1.0\n",
      "                      uk = True             spam : ham    =     91.7 : 1.0\n",
      "                  urgent = True             spam : ham    =     90.4 : 1.0\n",
      "                    code = True             spam : ham    =     87.4 : 1.0\n",
      "                      16 = True             spam : ham    =     78.9 : 1.0\n",
      "                delivery = True             spam : ham    =     66.1 : 1.0\n",
      "                   award = True             spam : ham    =     66.1 : 1.0\n",
      "                landline = True             spam : ham    =     65.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Most informative words\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "service in that set is 154 times more likely to be spam than ham.  Our model has a good accuracy rate on data that he has not seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References  \n",
    "https://www.kaggle.com/uciml/sms-spam-collection-dataset  \n",
    "https://github.com/sampepose/SpamClassifier/blob/master/naive_bayes.py \n",
    "https://github.com/JonathanKross/spambase/blob/master/spamalot.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
